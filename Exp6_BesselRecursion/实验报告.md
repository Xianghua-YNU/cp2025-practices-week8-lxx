# 实验六：球贝塞尔函数的递推关系与数值稳定性实验报告

## 1. 实验目的
1. 实现并比较球贝塞尔函数的向上和向下递推计算方法
2. 理解并掌握向下递推结果的归一化方法
3. 通过实验观察和分析不同递推方法的数值稳定性
4. 深入理解数值计算中的误差放大和抑制机制

## 2. 实验原理
### 2.1 球贝塞尔函数
球贝塞尔函数 $j_l(x)$ 满足二阶线性常微分方程：

$$ x^2 f''(x) + 2xf'(x) + [x^2 - l(l+1)]f(x) = 0 $$

最低阶的两个函数解析形式：

$$ j_0(x) = \frac{\sin x}{x} $$

$$ j_1(x) = \frac{\sin x}{x^2} - \frac{\cos x}{x} $$

### 2.2 递推关系
1. 向上递推：
   
$$ j_{l+1}(x) = \frac{2l+1}{x} j_l(x) - j_{l-1}(x) $$

2. 向下递推：
   
$$ j_{l-1}(x) = \frac{2l+1}{x} j_l(x) - j_{l+1}(x) $$

### 2.3 归一化方法
向下递推结果的归一化：

$$ j_l^\mathrm{normalized}(x) = j_l^\mathrm{compute}(x) \times \frac{j_0^\mathrm{analytic}(x)}{j_0^\mathrm{compute}(x)} $$

## 3. 实验方法
### 3.1 代码实现
1. `bessel_up(x, lmax)` 函数实现：
```
def bessel_up(x, lmax):
    j = np.zeros(lmax + 1)
    j[0] = np.sin(x) / x if x != 0 else 1.0
    if lmax >= 1:
        j[1] = (np.sin(x) / x - np.cos(x)) / x if x != 0 else 0.0
        for l in range(1, lmax):
            j[l+1] = (2*l + 1)/x * j[l] - j[l-1]
    return j
```

2. `bessel_down(x, lmax, m_start)` 函数实现：
```
def bessel_down(x, lmax, m_start=None):
    if m_start is None:
        m_start = lmax + 15
    
    # 初始化数组，从0到m_start+1
    j = np.zeros(m_start + 2)
    j[m_start + 1] = 0.0
    j[m_start] = 1.0
    
    # 向下递推
    for l in range(m_start, 0, -1):
        j[l-1] = (2*l + 1)/x * j[l] - j[l+1]
    
    # 归一化
    j0_analytic = np.sin(x)/x if x != 0 else 1.0
    norm_factor = j0_analytic / j[0]
    j_normalized = j[:lmax+1] * norm_factor
    
    return j_normalized
```

### 3.2 数据收集与处理
1. 测试点选取：x = 0.1, 1.0, 10.0
2. 计算范围：l = 0 到 25
3. 与scipy.special.spherical_jn比较
4. 误差计算方法

## 4. 实验结果
### 4.1 数值结果

![image](https://github.com/user-attachments/assets/d1dbdc7a-4c11-41c1-8956-4c1f3c92e37a)

### 4.2 误差分析图
![image](https://github.com/user-attachments/assets/0a3fce75-2370-4a4c-adbc-e838920a938a)
![image](https://github.com/user-attachments/assets/ac5560d3-bae4-4b62-88c9-1e54254ee409)
![image](https://github.com/user-attachments/assets/3082bd9a-fdee-4d43-8d94-77f4edabd4e2)

## 5. 分析与讨论
### 5.1 数值稳定性分析
1. 向上递推的不稳定性：
   - 失效区域分析（l > x时的表现）
     
当 l > x 时，向上递推开始表现出明显的不稳定性。

   - 误差放大机制分析
     
误差放大机制：递推关系中的系数 (2l+1)/x 随着 l 增大而增大，导致舍入误差被放大

   - 与球诺伊曼函数的关系
     
数学上，向上递推会混入球诺伊曼函数的成分，而诺伊曼函数在 l 增大时发散

2. 向下递推的稳定性：

向下递推在整个 l 范围内都保持稳定

   - 误差抑制机制
     
递推过程倾向于压制发散解，保留收敛解

   - 归一化的作用

归一化步骤确保最终结果与解析解一致

   - 计算精度分析

相对误差通常保持在机器精度（∼1e-15）量级，即使对于l≫x的情况仍保持稳定，归一化后与解析解的相对误差普遍小于1e-10。

### 5.2 计算效率比较
1. 两种方法的计算时间对比
2. 影响计算效率的因素分析

两种方法的计算复杂度相同，都是 O(lmax)；
向下递推需要额外的归一化步骤，但计算量可以忽略；
对于大 lmax，两种方法的计算时间相当。

## 6. 结论
1. 两种递推方法的适用条件
2. 数值稳定性的重要性
3. 归一化在提高计算精度中的作用

向上递推在 l < x 时计算准确，但在 l > x 时变得不稳定；
向下递推在所有情况下都稳定可靠，是计算高阶球贝塞尔函数的首选方法；
数值稳定性是递推算法设计中需要考虑的关键因素；
归一化步骤对保证向下递推结果的准确性至关重要。

## 7. 思考题
1. 为什么向上递推在l > x时会变得不稳定？

因为递推系数 (2l+1)/x 变大，放大了舍入误差；
数学上会混入发散解（诺伊曼函数）的成分

2. 向下递推为什么能够有效抑制误差？

递推过程天然压制发散解，
误差在递推过程中被平均化而不是放大

3. 如何选择合适的m_start值以保证计算精度？

经验上选择 m_start = lmax + 15 足够；
可以动态调整直到结果不再敏感于 m_start 的选择

## 附录：关键代码
```python
def bessel_up(x, lmax):
    j = np.zeros(lmax + 1)
    j[0] = np.sin(x) / x if x != 0 else 1.0
    if lmax >= 1:
        j[1] = (np.sin(x) / x - np.cos(x)) / x if x != 0 else 0.0
        for l in range(1, lmax):
            j[l+1] = (2*l + 1)/x * j[l] - j[l-1]
    return j

def bessel_down(x, lmax, m_start=None):
    if m_start is None:
        m_start = lmax + 15
    
    # 初始化数组，从0到m_start+1
    j = np.zeros(m_start + 2)
    j[m_start + 1] = 0.0
    j[m_start] = 1.0
    
    # 向下递推
    for l in range(m_start, 0, -1):
        j[l-1] = (2*l + 1)/x * j[l] - j[l+1]
    
    # 归一化
    j0_analytic = np.sin(x)/x if x != 0 else 1.0
    norm_factor = j0_analytic / j[0]
    j_normalized = j[:lmax+1] * norm_factor
    
    return j_normalized

def plot_comparison(x, lmax):
    l_values = np.arange(lmax + 1)
    j_up = bessel_up(x, lmax)
    j_down = bessel_down(x, lmax)
    j_scipy = spherical_jn(l_values, x)
    
    plt.figure(figsize=(12, 5))
    
    # 函数值比较
    plt.subplot(1, 2, 1)
    plt.semilogy(l_values, np.abs(j_up), 'o-', label='Upward')
    plt.semilogy(l_values, np.abs(j_down), 's-', label='Downward')
    plt.semilogy(l_values, np.abs(j_scipy), '^-', label='Scipy')
    plt.xlabel('Order l')
    plt.ylabel('|j_l(x)|')
    plt.title(f'Comparison of methods (x={x})')
    plt.legend()
    plt.grid(True, which="both", ls="-")
    
    # 相对误差比较
    plt.subplot(1, 2, 2)
    with np.errstate(divide='ignore', invalid='ignore'):
        rel_err_up = np.abs((j_up - j_scipy)/j_scipy)
        rel_err_down = np.abs((j_down - j_scipy)/j_scipy)
    
    plt.semilogy(l_values, rel_err_up, 'o-', label='Upward error')
    plt.semilogy(l_values, rel_err_down, 's-', label='Downward error')
    plt.xlabel('Order l')
    plt.ylabel('Relative error')
    plt.title(f'Relative error (x={x})')
    plt.legend()
    plt.grid(True, which="both", ls="-")
    
    plt.tight_layout()
    plt.show()
```
