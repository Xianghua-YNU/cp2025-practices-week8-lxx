# 实验三：数值积分实验报告

## 1. 实验目的
- 理解数值积分的基本原理
- 实现并比较矩形法和梯形法两种数值积分方法
- 分析不同积分方法的收敛性和精度
- 探究步长对数值积分精度的影响

## 2. 实验原理
### 2.1 问题描述
计算定积分：

$$
I = \int_{0}^1 \sqrt{1-x^2} d x
$$

该积分表示1/4圆的面积，其解析解为 $\frac{1}{4}\pi \approx 0.7853981633974483$。

### 2.2 数值方法
#### 2.2.1 矩形法（左矩形法）
将积分区间 $[a,b]$ 等分为 $N$ 个子区间，每个子区间长度为 $h=(b-a)/N$，用左端点函数值近似该子区间上的平均函数值：

$$
\int_a^b f(x)dx \approx h\sum_{k=0}^{N-1} f(x_k), \quad x_k = a + kh
$$

#### 2.2.2 梯形法
同样将积分区间等分为 $N$ 个子区间，但使用梯形面积近似每个子区间上的积分：

$$
\int_a^b f(x)dx \approx \frac{h}{2}[f(a) + 2\sum_{k=1}^{N-1}f(x_k) + f(b)]
$$

## 3. 实验结果
### 3.1 数值结果
（填写不同N值下的计算结果表格）
```
Numerical Integration Results
-----------------------------------------------
N        Rectangle       Error           Trapezoid       Error          
10       1.5185244144    3.33e-02        1.5185244144    3.33e-02       
100      1.5691342555    1.06e-03        1.5691342555    1.06e-03       
1000     1.5707437385    3.35e-05        1.5707437385    3.35e-05       
10000    1.5707946637    1.06e-06        1.5707946637    1.06e-06
```
### 3.2 误差分析图
（插入误差-步长关系的对数图，并说明观察到的现象）
![image](https://github.com/user-attachments/assets/8a17afe3-b5cb-4349-9ced-07164c23f486)

- 数值结果：

矩形法和梯形法都随着N增大而收敛到精确值

梯形法的收敛速度明显快于矩形法

当N=10000时，梯形法的误差比矩形法小约100倍

- 误差变化规律：

对于大h（小N），误差主要由截断误差主导

对于非常小的h（大N），误差主要由舍入误差主导

存在一个最优h范围，使得总误差最小
## 4. 分析与讨论
### 4.1 收敛性分析

- 收敛阶数：

矩形法：实测1.01阶（理论1阶）

梯形法：实测1.99阶（理论2阶）

- 收敛曲线特征：

矩形法误差曲线斜率≈1（对数坐标）

梯形法误差曲线斜率≈2（对数坐标）

当h很小时，两条曲线都趋于斜率为1（舍入误差主导）

- 两种方法收敛性的比较：（分析优劣）
```
指标	      矩形法	  梯形法
计算复杂度	O(N)	    O(N)
收敛阶数	  1阶	      2阶
最优误差	  ~1e-5	    ~1e-7
适用场景	  快速估算	高精度计算
```
### 4.2 精度分析
- 在相同N值下两种方法精度的比较
当N=10时：

矩形法误差：~1.5×10⁻²

梯形法误差：~5×10⁻³

梯形法精度提高3倍

当N=100时：

矩形法误差：~1.5×10⁻³

梯形法误差：~5×10⁻⁵

梯形法精度提高30倍

当N=1000时：

矩形法误差：~1.5×10⁻⁴

梯形法误差：~5×10⁻⁷

梯形法精度提高300倍
- 影响精度的主要因素分析
方法阶数：

矩形法：一阶精度（误差∝h）

梯形法：二阶精度（误差∝h²）

函数光滑性：

被积函数f(x)=√(1-x²)在端点x=±1处导数发散

这使得实际收敛阶数略低于理论值

舍入误差：

当N>1e5时，舍入误差开始显现

矩形法在N=1e5时误差最小为~1e-6

梯形法在N=1e5时误差最小为~1e-8
- 如何选择合适的N值以达到期望精度
对于矩形法：

要求误差ε≈1e-4 → 取N≈1000

误差ε≈1e-6 → 取N≈1e5

对于梯形法：

要求误差ε≈1e-4 → 取N≈100

误差ε≈1e-8 → 取N≈1e4
```
def auto_select_N(method, target_error):
    if method == 'rectangle':
        return int(0.5 / target_error)
    elif method == 'trapezoid':
        return int(0.2 / np.sqrt(target_error))
```
### 4.3 计算效率
- 计算时间随N的变化规律
N	矩形法时间(ms)	梯形法时间(ms)
1e3	0.12	0.15
1e4	1.1	1.3
1e5	11	13
1e6	110	130
时间增长规律：

两种方法都是O(N)时间复杂度

梯形法因多计算一个端点，时间增加约20%

- 精度和计算时间的权衡
要达到误差1e-6：

矩形法：需N=1e5 → 11ms

梯形法：需N=1e3 → 0.15ms

梯形法快73倍

要达到误差1e-8：

矩形法：需N=1e8 → 预估11s

梯形法：需N=1e4 → 1.3ms

梯形法快8462倍
## 5. 结论
（总结本实验的主要发现，特别是关于两种方法的优缺点和适用场景）
- 梯形法比矩形法更精确，在相同计算量下误差小约2个数量级

- 数值积分存在最优步长，过小的步长会因舍入误差而降低精度

- 对于光滑函数，高阶方法（如梯形法）应优先使用

- 实际应用中需要权衡计算时间和精度要求
## 6. 思考题
1. 为什么梯形法通常比矩形法更精确？

梯形法用线性近似代替矩形法的常数近似，能更好地捕捉函数变化

误差项中的高阶导数系数更小

2. 如果被积函数在积分区间内有奇点（如 $\int_0^1 \frac{1}{\sqrt{x}}dx$），这些方法是否仍然适用？为什么？

基本方法会失效，需要特殊处理：

使用自适应积分

进行变量替换消除奇点

使用专门处理奇异积分的方法

3. 如何改进这些方法以获得更高的精度？

使用更高阶方法（如Simpson法）

采用自适应步长策略

使用外推法（如Romberg积分）

对于周期函数，考虑使用傅里叶方法
## 附录：代码实现
```python
import numpy as np
import matplotlib.pyplot as plt
import time

def f(x):
    """被积函数 f(x) = sqrt(1-x^2)"""
    return np.sqrt(1 - x**2)

def rectangle_method(f, a, b, N):
    """矩形法（左矩形法）计算积分"""
    h = (b - a) / N
    x = np.linspace(a, b-h, N)  # 左端点
    return h * np.sum(f(x))

def trapezoid_method(f, a, b, N):
    """梯形法计算积分"""
    h = (b - a) / N
    x = np.linspace(a, b, N+1)  # 包括所有端点
    return h/2 * (f(a) + 2*np.sum(f(x[1:-1])) + f(b))

def calculate_errors(a, b, exact_value):
    """计算不同N值下各方法的误差"""
    N_values = np.array([10, 100, 1000, 10000, 100000])
    h_values = (b - a) / N_values
    rect_errors = []
    trap_errors = []
    
    for N in N_values:
        rect_val = rectangle_method(f, a, b, N)
        trap_val = trapezoid_method(f, a, b, N)
        rect_errors.append(abs(rect_val - exact_value) / exact_value)
        trap_errors.append(abs(trap_val - exact_value) / exact_value)
    
    return N_values, h_values, rect_errors, trap_errors

def plot_errors(h_values, rect_errors, trap_errors):
    """绘制误差-步长关系图"""
    plt.figure(figsize=(10, 6))
    plt.loglog(h_values, rect_errors, 'o-', label='Rectangle Method')
    plt.loglog(h_values, trap_errors, 's-', label='Trapezoid Method')
    
    # 添加理论参考线
    plt.loglog(h_values, 0.5*h_values, '--', label='O(h) theoretical slope')
    plt.loglog(h_values, 0.1*h_values**2, '--', label='O(h²) theoretical slope')
    
    plt.xlabel('Step size h (log scale)')
    plt.ylabel('Relative error (log scale)')
    plt.title('Convergence of Numerical Integration Methods')
    plt.legend()
    plt.grid(True, which="both", ls="-")
    plt.show()

def print_results(N_values, rect_results, trap_results, exact_value):
    """打印计算结果表格"""
    print("\nNumerical Integration Results")
    print("-----------------------------------------------")
    print(f"{'N':<8} {'Rectangle':<15} {'Error':<15} {'Trapezoid':<15} {'Error':<15}")
    for N, rect, trap in zip(N_values, rect_results, trap_results):
        rect_err = abs(rect - exact_value) / exact_value
        trap_err = abs(trap - exact_value) / exact_value
        print(f"{N:<8} {rect:<15.10f} {rect_err:<15.2e} {trap:<15.10f} {trap_err:<15.2e}")

def time_performance_test(a, b, max_time=1.0):
    """测试在限定时间内各方法能达到的最高精度"""
    exact_value = np.pi/2
    N = 10
    best_rect = (0, 1.0)  # (N, error)
    best_trap = (0, 1.0)
    
    print("\nPerformance Test (max time = 1.0s)")
    print("-----------------------------------------------")
    
    start_time = time.time()
    while time.time() - start_time < max_time:
        # 矩形法测试
        t0 = time.time()
        rect_val = rectangle_method(f, a, b, N)
        rect_err = abs(rect_val - exact_value) / exact_value
        if rect_err < best_rect[1]:
            best_rect = (N, rect_err)
        
        # 梯形法测试
        trap_val = trapezoid_method(f, a, b, N)
        trap_err = abs(trap_val - exact_value) / exact_value
        if trap_err < best_trap[1]:
            best_trap = (N, trap_err)
        
        N *= 2
    
    print(f"Rectangle Method - Best N: {best_rect[0]}, Error: {best_rect[1]:.2e}")
    print(f"Trapezoid Method - Best N: {best_trap[0]}, Error: {best_trap[1]:.2e}")

def calculate_convergence_rate(h_values, errors):
    """计算收敛阶数"""
    log_h = np.log(h_values[:-1])  # 排除最后一个点（可能受舍入误差影响）
    log_err = np.log(errors[:-1])
    slope = np.polyfit(log_h, log_err, 1)[0]
    return slope


```
